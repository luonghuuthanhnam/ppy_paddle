{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import uuid\n",
    "import numpy as np\n",
    "import LineOCR\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"D:/PPYData/test/\"\n",
    "raw_labeled_data = open(f\"{data_dir}Label.txt\", \"r\",  encoding=\"utf-8\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_key_cls = [\n",
    "    \"hospital_name\",\n",
    "    \"department\",\n",
    "    \"patient_name\",\n",
    "    \"age\",\n",
    "    \"gender\",\n",
    "    \"admission_date\",\n",
    "    \"discharge_date\",\n",
    "    \"diagnose\",\n",
    "    \"sign_date\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lineDetAndOCR = LineOCR.ProcessImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path, test_json = raw_labeled_data[0].split(\"\\t\")\n",
    "img_path = data_dir.replace(\"test\", img_path)[:-1]\n",
    "raw_img = cv2.imread(img_path)\n",
    "djson = json.loads(test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "croped_dir = \"croped_for_ocr/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [01:29<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "for each_file in tqdm.tqdm(raw_labeled_data):\n",
    "    img_path, test_json = each_file.split(\"\\t\")\n",
    "    img_path = data_dir.replace(\"test\", img_path)[:-1]\n",
    "    raw_img = cv2.imread(img_path)\n",
    "    djson = json.loads(test_json)\n",
    "    for each in djson:\n",
    "        if each[\"key_cls\"] in selected_key_cls:\n",
    "            cls = each[\"key_cls\"]\n",
    "            transcription = each[\"transcription\"]\n",
    "            test_points = each[\"points\"]\n",
    "            croped_img, _points = lineDetAndOCR.crop_line_v2(raw_img, test_points, convert_gray=True)\n",
    "            pil_croped_img = Image.fromarray(croped_img)\n",
    "            text, prob = lineDetAndOCR.individual_OCR(pil_croped_img)\n",
    "            img_name = str(uuid.uuid4()) + \".jpg\"\n",
    "            line = f\"{img_name}\\t{text}\\t{prob}\"\n",
    "            lines.append(line)\n",
    "            save_path = croped_dir + img_name\n",
    "            cv2.imwrite(save_path ,croped_img)\n",
    "\n",
    "            # print(f\"{cls}: {transcription}\")\n",
    "            # print(f\"prediction: {text}\")\n",
    "            # print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname, text, score = [],[],[]\n",
    "for each in lines:\n",
    "    _fname, _text, _score = each.split(\"\\t\")\n",
    "    fname.append(_fname)\n",
    "    text.append(_text)\n",
    "    score.append(_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2022-10-24 12:30:15,781 utils.py:147] Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict({\n",
    "    \"fname\": fname,\n",
    "    \"text\": text,\n",
    "    \"score\": score,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values(\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlines = []\n",
    "for idx in range(len(sorted_df)):\n",
    "    row = sorted_df.iloc[idx]\n",
    "    _fname = row[\"fname\"]\n",
    "    _text = row[\"text\"]\n",
    "    _score = row[\"score\"]\n",
    "    line = f\"{_fname}\\t{_text}\\t{_score}\"\n",
    "    wlines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ocr_prediction.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(\"\\n\".join(wlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path, test_json = raw_labeled_data[5].split(\"\\t\")\n",
    "img_path = data_dir.replace(\"test\", img_path)[:-1]\n",
    "raw_img = cv2.imread(img_path)\n",
    "djson = json.loads(test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transcription': 'SƠ Y TẾ THANH HÓA',\n",
       " 'points': [[95, 107], [288, 99], [288, 117], [95, 125]],\n",
       " 'difficult': False,\n",
       " 'key_cls': 'None'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "djson[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 95 107]\n",
      "  [288  99]\n",
      "  [288 117]\n",
      "  [ 95 125]]]\n",
      "(0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "points = djson[3][\"points\"]\n",
    "croped, temp = lineDetAndOCR.crop_line_v2(raw_img, points, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(738, 1024, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon = djson[3][\"points\"]\n",
    "tuple_polygon = []\n",
    "for each in polygon:\n",
    "    tuple_polygon.append(tuple(each))\n",
    "mask = np.zeros((738, 1024))\n",
    "myROI = tuple_polygon  # (x, y)\n",
    "roi_img = cv2.fillPoly(mask, [np.array(myROI)], 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"test.jpg\", roi_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 95 107]\n",
      "  [288  99]\n",
      "  [288 117]\n",
      "  [ 95 125]]]\n",
      "(0, 0, 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from turtle import fillcolor\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# original image\n",
    "# -1 loads as-is so if it will be 3 or 4 channel as the original\n",
    "# image = cv2.imread('image.png', -1)\n",
    "image = raw_img.copy()\n",
    "# mask defaulting to black for 3-channel and transparent for 4-channel\n",
    "# (of course replace corners with yours)\n",
    "\n",
    "polygon = djson[3][\"points\"]\n",
    "list_x = [x for x,y in polygon]\n",
    "list_y = [y for x,y in polygon]\n",
    "xmin = min(list_x)\n",
    "xmax = max(list_x)\n",
    "ymin = min(list_y)\n",
    "ymax = max(list_y)\n",
    "tuple_polygon = []\n",
    "for each in polygon:\n",
    "    tuple_polygon.append(tuple(each))\n",
    "    \n",
    "mask = np.ones(image.shape, dtype=np.uint8)*255\n",
    "\n",
    "# roi_corners = np.array([[(10,10), (300,300), (10,300)]], dtype=np.int32)\n",
    "roi_corners = [tuple_polygon]\n",
    "roi_corners = np.array(roi_corners)\n",
    "print(roi_corners)\n",
    "# fill the ROI so it doesn't get wiped out when the mask is applied\n",
    "channel_count = image.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "ignore_mask_color = (0,)*channel_count\n",
    "print(ignore_mask_color)\n",
    "cv2.fillPoly(mask, roi_corners, ignore_mask_color)\n",
    "# from Masterfool: use cv2.fillConvexPoly if you know it's convex\n",
    "\n",
    "# apply the mask\n",
    "masked_image = cv2.bitwise_or(image, mask)\n",
    "\n",
    "croped_mask = masked_image[ymin:ymax, xmin:xmax]\n",
    "# save the result\n",
    "cv2.imwrite('image_masked.png', croped_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 73/226 [00:00<00:01, 102.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file D:/PPYData/test/60.jpeg is missing ADMISSION DATE\n",
      "file D:/PPYData/test/60.jpeg is missing DISCHARGE DATE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 132/226 [00:01<00:01, 82.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file D:/PPYData/test/123.jpeg MULTI ADMISSION DATE\n",
      "file D:/PPYData/test/123.jpeg MULTI DISCHARGE DATE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 195/226 [00:02<00:00, 64.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file D:/PPYData/test/194.jpeg MULTI DISCHARGE DATE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 79.15it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "for each_file in tqdm.tqdm(raw_labeled_data):\n",
    "    img_path, test_json = each_file.split(\"\\t\")\n",
    "    img_path = data_dir.replace(\"test\", img_path)[:-1]\n",
    "    raw_img = cv2.imread(img_path)\n",
    "    djson = json.loads(test_json)\n",
    "    have_adm_date = False\n",
    "    have_dis_date = False\n",
    "    adm_count = 0\n",
    "    dis_count = 0\n",
    "    for each in djson:\n",
    "        if each[\"key_cls\"]== \"admission_date\":\n",
    "            have_adm_date = True\n",
    "            adm_count+=1\n",
    "        elif each[\"key_cls\"]== \"discharge_date\":\n",
    "            have_dis_date = True\n",
    "            dis_count+=1\n",
    "        # if have_adm_date == True and have_dis_date == True:\n",
    "        #     break\n",
    "    if have_adm_date == False:\n",
    "        print(f\"file {img_path} is missing ADMISSION DATE\")\n",
    "    if have_dis_date == False:\n",
    "        print(f\"file {img_path} is missing DISCHARGE DATE\")\n",
    "    if adm_count>1:\n",
    "        print(f\"file {img_path} MULTI ADMISSION DATE\")\n",
    "    if dis_count>1:\n",
    "        print(f\"file {img_path} MULTI DISCHARGE DATE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 77/226 [00:00<00:01, 106.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file D:/PPYData/test/60.jpeg is missing AGE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 199/226 [00:02<00:00, 83.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file D:/PPYData/test/190.jpeg is missing AGE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 92.07it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "for each_file in tqdm.tqdm(raw_labeled_data):\n",
    "    img_path, test_json = each_file.split(\"\\t\")\n",
    "    img_path = data_dir.replace(\"test\", img_path)[:-1]\n",
    "    raw_img = cv2.imread(img_path)\n",
    "    djson = json.loads(test_json)\n",
    "    have_age = False\n",
    "    for each in djson:\n",
    "        if have_age ==False and each[\"key_cls\"]== \"diagnose\":\n",
    "            have_age = True\n",
    "    if have_age == False:\n",
    "        print(f\"file {img_path} is missing AGE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc5644fd2b52d511b211cf140a1e1d228fa8006a12c8d99adabf32e3d6df441d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
