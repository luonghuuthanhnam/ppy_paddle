{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import importlib\n",
    "\n",
    "import py_vncorenlp\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import preprocess_img\n",
    "import LineOCR\n",
    "importlib.reload(LineOCR)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import graph\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "import torch_geometric\n",
    "importlib.reload(graph)\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import ChebConv, GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\").type\n",
    "\n",
    "\n",
    "ID2LABEL_DICT = {\n",
    "    0: \"None\",\n",
    "    1: \"sign_date\",\n",
    "    2: \"diagnose\",\n",
    "    3:\"hospital_name\",\n",
    "    4:\"address\",\n",
    "    5:\"age\",\n",
    "    6:\"treatment\",\n",
    "    7:\"patient_name\",\n",
    "    8:\"admission_date\",\n",
    "    9:\"discharge_date\",\n",
    "    10:\"gender\",\n",
    "    11:\"document_type\",\n",
    "    12:\"department\",\n",
    "    13:\"note\",\n",
    "    14:\"BHYT\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Text Segmentation engine\n",
    "# rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir=r'D:\\PPYCode\\OCR\\ppy_paddle\\weights\\nlp\\vncorenlp')\n",
    "# phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "# %cd ../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all models\n",
    "preprocessImage = preprocess_img.PreprocessImage()\n",
    "lineDetAndOCR = LineOCR.ProcessImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.imread(r\"imgs_test\\705.jpeg\")\n",
    "test_img = preprocessImage(test_img)\n",
    "# lines, t = lineDetInfer.line_det_infer(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = test_img.copy()\n",
    "# for line in lines:\n",
    "#     pts = line.astype(int)\n",
    "#     pts = pts.reshape((-1, 1, 2))\n",
    "    \n",
    "#     isClosed = True\n",
    "    \n",
    "#     # Blue color in BGR\n",
    "#     color = (255, 0, 0)\n",
    "    \n",
    "#     # Line thickness of 2 px\n",
    "#     thickness = 2\n",
    "    \n",
    "#     image = cv2.polylines(image, [pts],\n",
    "#                         isClosed, color, thickness)\n",
    "\n",
    "# display(Image.fromarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lineDetAndOCR.begin_recognize_text(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kie_gcn\n",
    "from kie_gcn import InvoiceGCN\n",
    "kieGCN = kie_gcn.KieGCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kie_df = kieGCN(result, test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for iter in range(len(result[\"croped_pil_img\"])):\n",
    "#     line_img = result[\"croped_pil_img\"][iter]\n",
    "#     text = result[\"text\"][iter]\n",
    "#     ocr_score = result[\"ocr_score\"][iter]\n",
    "#     display(line_img)\n",
    "#     print(f\"{text} \\t {ocr_score}\")\n",
    "#     print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_xmin = []\n",
    "list_ymin = []\n",
    "list_xmax = []\n",
    "list_ymax = []\n",
    "list_Object = []\n",
    "\n",
    "for iter in range(len(result[\"bbox\"])):\n",
    "    xmin, ymin, xmax, ymax = result[\"bbox\"][iter]\n",
    "    text = result[\"text\"][iter]\n",
    "    list_xmin.append(xmin)\n",
    "    list_xmax.append(xmax)\n",
    "    list_ymin.append(ymin)\n",
    "    list_ymax.append(ymax)\n",
    "    list_Object.append(text)\n",
    "single_df = {\n",
    "    \"xmin\": list_xmin,\n",
    "    \"xmax\": list_xmax,\n",
    "    \"ymin\": list_ymin,\n",
    "    \"ymax\": list_ymax,\n",
    "    \"Object\": list_Object,\n",
    "    \"labels\": [\"None\"]*len(list_Object)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_df = pd.DataFrame.from_dict(single_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_df.to_excel(\"temp_data/temp_gcn/csv/temp.xlsx\")\n",
    "cv2.imwrite(\"temp_data/temp_gcn/img/temp.jpg\", test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_features(sentence):\n",
    "    segmented_sentence = rdrsegmenter.word_segment(sentence)\n",
    "    tokenized_sentence = torch.tensor([tokenizer.encode(segmented_sentence[0])])\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        features = phobert(tokenized_sentence)\n",
    "    return features\n",
    "\n",
    "def make_sent_bert_features(text):\n",
    "    features = get_sentence_features(text)\n",
    "    return features[1][0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'temp'\n",
    "connect = graph.Grapher(file)\n",
    "G,result, df = connect.graph_formation(export_graph=False)\n",
    "df = connect.relative_distance(export_document_graph = False)\n",
    "individual_data = from_networkx(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "            \"rd_b\",\n",
    "            \"rd_r\",\n",
    "            \"rd_t\",\n",
    "            \"rd_l\",\n",
    "            \"line_number\",\n",
    "            \"n_upper\",\n",
    "            \"n_alpha\",\n",
    "            \"n_spaces\",\n",
    "            \"n_numeric\",\n",
    "            \"n_special\",\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inference_data(df, individual_data):\n",
    "        text_features = []\n",
    "        for _, row in df.iterrows():\n",
    "            text_features.append(make_sent_bert_features(row[\"Object\"]))\n",
    "        text_features = np.asarray(text_features, dtype=np.float32)\n",
    "\n",
    "        numeric_features = df[feature_cols].values.astype(np.float32)\n",
    "\n",
    "        features = np.concatenate((numeric_features, text_features), axis=1)\n",
    "        features = torch.tensor(features)\n",
    "\n",
    "        for col in df.columns:\n",
    "            try:\n",
    "                df[col] = df[col].str.strip()\n",
    "            except AttributeError as e:\n",
    "                pass\n",
    "        text = df[\"Object\"].values\n",
    "        individual_data.x = features\n",
    "\n",
    "        individual_data.text = text\n",
    "\n",
    "        test_list_of_graphs = []\n",
    "        test_list_of_graphs.append(individual_data)\n",
    "\n",
    "        test_one_data = \"\"\n",
    "        test_one_data = torch_geometric.data.Batch.from_data_list(test_list_of_graphs)\n",
    "        test_one_data.edge_attr = None\n",
    "        return test_one_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data = preprocess_inference_data(df, individual_data)\n",
    "test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvoiceGCN(nn.Module):\n",
    "    def __init__(self, input_dim, chebnet=False, n_classes=5, dropout_rate=0.2, K=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        if chebnet:\n",
    "            self.conv1 = ChebConv(self.input_dim, 64, K=K)\n",
    "            # self.conv2 = ChebConv(64, 32, K=K)\n",
    "            self.conv3 = ChebConv(64, 64, K=K)\n",
    "            self.conv4 = ChebConv(64, self.n_classes, K=K)\n",
    "        else:\n",
    "            self.conv1 = GCNConv(self.first_dim, 64, improved=True, cached=True)\n",
    "            self.conv2 = GCNConv(64, 32, improved=True, cached=True)\n",
    "            self.conv3 = GCNConv(32, 16, improved=True, cached=True)\n",
    "            self.conv4 = GCNConv(16, self.n_classes, improved=True, cached=True)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # for transductive setting with full-batch update\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        x = F.dropout(F.relu(self.conv1(x, edge_index, edge_weight)), p=self.dropout_rate, training=self.training)\n",
    "        # x = F.dropout(F.relu(self.conv2(x, edge_index, edge_weight)), p=self.dropout_rate, training=self.training)\n",
    "        x = F.dropout(F.relu(self.conv3(x, edge_index, edge_weight)), p=self.dropout_rate, training=self.training)\n",
    "        x = self.conv4(x, edge_index, edge_weight)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(r\"D:\\PPYCode\\OCR\\ppy_paddle\\weights\\gcn\\GCN_221017.pth\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds= model(test_data)\n",
    "max_idx_Y_pred= y_preds.max(dim=1)[1].cpu().numpy()\n",
    "shorten_pred = [y_preds[idx][max_idx_Y_pred[idx]] for idx in range(len(max_idx_Y_pred))]\n",
    "pred_probs = torch.exp(torch.tensor(shorten_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = [ID2LABEL_DICT[each] for each in list(max_idx_Y_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pred_class\"] = lb\n",
    "df[\"confidence_score\"] = pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[[\"index\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"Object\", \"pred_class\", \"confidence_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"confidence_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, each in enumerate(y_preds):\n",
    "    text = test_data.text[0][idx]\n",
    "    pred_class = ID2LABEL_DICT[each]\n",
    "    print(text + '\\t' + pred_class)\n",
    "    print(\"-----------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End2End inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import preprocess_img\n",
    "import LineOCR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kie_gcn\n",
    "from kie_gcn import InvoiceGCN\n",
    "import time\n",
    "import dateutil.parser as dparser\n",
    "import unidecode\n",
    "import datefinder\n",
    "import re\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessImage = preprocess_img.PreprocessImage()\n",
    "lineDetAndOCR = LineOCR.ProcessImage(detection_model_path=\"./PaddleOCR/pretrained_models/exported_det_model_221025\", text_recognition_model_path=\"./weights/ocr/ocr_221025.pth\")\n",
    "kieGCN = kie_gcn.KieGCN(gcn_model_path=\"./weights/gcn/GCN_221026.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_predicted(label:str, predicted_df:pd.DataFrame, sort_top_down = False) -> list: \n",
    "    extracted_row = predicted_df[predicted_df[\"pred_label\"]==label]\n",
    "    if sort_top_down == True:\n",
    "        extracted_row = extracted_row.sort_values(\"ymax\", ascending=True)\n",
    "    else:\n",
    "        extracted_row = extracted_row.sort_values(\"confidence_score\", ascending=False)\n",
    "    extracted_row = extracted_row[\"Object\"].to_list()\n",
    "    extracted_row = [each.strip() for each in extracted_row]\n",
    "    return extracted_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENT_NAME_REMOVE_LIST=[\n",
    "    \"Họ và tên người bệnh\",\n",
    "    \"họ và tên người bệnh\",\n",
    "    \"Họ và tên\",\n",
    "    \"họ và tên\",\n",
    "    \"Họ tên\",\n",
    "    \"họ tên\",\n",
    "]\n",
    "\n",
    "def patient_name_regularization(raw_patient_name):\n",
    "    shorten_patient_name = raw_patient_name\n",
    "    count_spliter = raw_patient_name.count(\":\")\n",
    "    if count_spliter>0:\n",
    "        shorten_patient_name = raw_patient_name.split(\":\")[-1]\n",
    "    for each in PATIENT_NAME_REMOVE_LIST:\n",
    "        shorten_patient_name = shorten_patient_name.replace(each, \"\")\n",
    "    return shorten_patient_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date_with_re(raw_date):\n",
    "    pattern = \"\\d+[/-]\\d+[/-]\\d+\"\n",
    "    temp_date = raw_date.replace(\"\\\\\",\"/\")\n",
    "    temp_date = raw_date.replace(\" \",\"\")\n",
    "    temp_date = re.findall(pattern=pattern, string=temp_date)\n",
    "    list_result = []\n",
    "    for each in temp_date:\n",
    "        for splitter in [\"/\", \"-\"]:\n",
    "            if splitter in each:\n",
    "                d, m, y = each.split(splitter)\n",
    "                list_result.append((d,m,y))\n",
    "                break\n",
    "    return list_result\n",
    "\n",
    "def vn_date_parser(date_raw_text):\n",
    "    unaccented_string = unidecode.unidecode(date_raw_text).lower()\n",
    "    day_idx = -1\n",
    "    day_val = -1\n",
    "    month_idx = -1\n",
    "    month_val = -1\n",
    "    year_idx = -1 \n",
    "    year_val = -1\n",
    "    \n",
    "    list_dates = parse_date_with_re(unaccented_string)\n",
    "    if len(list_dates) ==0:\n",
    "        unaccented_string = re.sub('(\\d+(\\.\\d+)?)', r'\\1 ', unaccented_string) #append space between mixed digit and charactor\n",
    "        unaccented_string = re.sub(' +', ' ', unaccented_string)\n",
    "        elms = unaccented_string.split(\" \")\n",
    "        max_idx = len(elms) -1\n",
    "        \n",
    "        #Parse Day\n",
    "        try:\n",
    "            day_idx = elms.index(\"ngay\") + 1\n",
    "            temp_day_val = int(elms[day_idx])\n",
    "            if temp_day_val in range(1,32):\n",
    "                day_val = temp_day_val\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            # print(\"***cannot parse DAY***\")\n",
    "            pass\n",
    "\n",
    "        #Parse Month\n",
    "        try:\n",
    "            month_idx = elms.index(\"thang\") + 1\n",
    "            temp_month_val = int(elms[month_idx])\n",
    "            if temp_month_val in range(1,13):\n",
    "                month_val = temp_month_val\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            # print(\"***cannot parse Month***\")\n",
    "            pass\n",
    "\n",
    "        \n",
    "        #Parse Year\n",
    "        try:\n",
    "            year_idx = elms.index(\"nam\") + 1\n",
    "            temp_year_val = int(elms[year_idx])\n",
    "            if temp_year_val in range(1900,2100):\n",
    "                year_val = temp_year_val\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            # print(\"***cannot parse Year***\")\n",
    "            pass\n",
    "    else:\n",
    "        day_val, month_val, year_val = list_dates[0]\n",
    "    return day_val, month_val, year_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AGE_ANCHOR_LIST = [\n",
    "    \"Tuổi\",\n",
    "    \"tuổi\",\n",
    "    \"Năm sinh\",\n",
    "    \"năm sinh\",\n",
    "    \"Ngày sinh\",\n",
    "    \"ngày sinh\",\n",
    "    \"Sinh ngày\",\n",
    "    \"sinh ngày\"\n",
    "]\n",
    "\n",
    "GENDER_ANCHOR_LIST = [\n",
    "    \"Giới tính\",\n",
    "    \"giới tính\",\n",
    "    \"Giới\",\n",
    "    \"giới\",\n",
    "    \"Nam/Nữ\",\n",
    "    \"Nam/nữ\",\n",
    "    \"nam/nữ\",\n",
    "    \"Nam/ Nữ\",\n",
    "    \"Nam/ nữ\",\n",
    "    \"nam/ nữ\",\n",
    "]\n",
    "\n",
    "def check_mixed_age_gender(raw_text):\n",
    "    age = None\n",
    "    gender = None\n",
    "    count_spliter = raw_text.count(\":\")\n",
    "    is_mixed_age_gender = False\n",
    "    if count_spliter>1:\n",
    "        is_mixed_age_gender = True\n",
    "    temp_age_elm = False\n",
    "    temp_gender_elm = False\n",
    "    for each in AGE_ANCHOR_LIST:\n",
    "        if each in raw_text:\n",
    "            temp_age_elm = True\n",
    "            break\n",
    "    for each in GENDER_ANCHOR_LIST:\n",
    "        if each in raw_text:\n",
    "            temp_gender_elm = True\n",
    "            break\n",
    "    if temp_age_elm + temp_gender_elm ==2:\n",
    "        is_mixed_age_gender = True\n",
    "\n",
    "    if is_mixed_age_gender:\n",
    "        #Mixed age and gender check\n",
    "        print(\"**mixed age and gender**\")\n",
    "        parts = raw_text.split(\":\")\n",
    "        list_number = re.findall(r'\\d+', raw_text)\n",
    "        if len(list_number)==1:\n",
    "            age = list_number[0]\n",
    "            unit_flag = sum([True if each in parts[1].lower() else False for each in [\"th\", \"tháng\"]])\n",
    "            if unit_flag != 0:\n",
    "                age = int(age)/12\n",
    "        \n",
    "        words = raw_text.split(\" \")\n",
    "        if words[-1].lower().strip() == \"nam\":\n",
    "            gender = \"Nam\"\n",
    "        elif words[-1].lower().strip() == \"nữ\":\n",
    "            gender = \"Nữ\"\n",
    "        \n",
    "        \n",
    "        if len(list_number) > 1:\n",
    "            # print(\"Check birthday\")\n",
    "            try:\n",
    "                # birthday = dparser.parse(raw_text,fuzzy=True, dayfirst = True)\n",
    "                d,m,y = vn_date_parser(raw_text)\n",
    "                age = f\"{d}/{m}/{y}\"\n",
    "            except:\n",
    "                print(\"***cannot parse date from:\", raw_text)\n",
    "            #Check birthday\n",
    "            pass\n",
    "    return age, gender\n",
    "\n",
    "\n",
    "def age_regularization(raw_age):\n",
    "    age = \"\"\n",
    "    gender = None\n",
    "    count_spliter = raw_age.count(\":\")\n",
    "\n",
    "    temp_age, temp_gender = check_mixed_age_gender(raw_age)\n",
    "    if temp_age != None:\n",
    "        age = temp_age\n",
    "    if temp_gender != None:\n",
    "        gender = temp_gender\n",
    "\n",
    "    elif count_spliter == 1:\n",
    "        left_part, right_part = raw_age.split(\":\")\n",
    "        left_part = left_part.strip()\n",
    "        right_part = right_part.strip()\n",
    "        for age_anchor in AGE_ANCHOR_LIST:\n",
    "            if age_anchor in left_part:\n",
    "                list_number = re.findall(r'\\d+', right_part)\n",
    "                if len(list_number)==1:\n",
    "                    age = list_number[0]\n",
    "                    unit_flag = sum([True if each in right_part.lower() else False for each in [\"th\", \"tháng\"]])\n",
    "                    if unit_flag != 0:\n",
    "                        age = int(age)/12\n",
    "                elif len(list_number) > 1:\n",
    "                    # print(\"Check birthday\")\n",
    "                    try:\n",
    "                        d,m,y = vn_date_parser(raw_age)\n",
    "                        age = f\"{d}/{m}/{y}\"\n",
    "                    except:\n",
    "                        print(\"***cannot parse date from:\", raw_age)\n",
    "                    #Check birthday\n",
    "                break\n",
    "\n",
    "    elif count_spliter == 0:\n",
    "        list_number = re.findall(r'\\d+', raw_age)\n",
    "        if len(list_number) ==1:\n",
    "            age = list_number[0]\n",
    "            unit_flag = sum([True if each in raw_age.lower() else False for each in [\"th\", \"tháng\"]])\n",
    "            if unit_flag != 0:\n",
    "                age = int(age)/12\n",
    "        elif len(list_number) >1:\n",
    "            #Check birthday\n",
    "            # print(\"Check birthday\")\n",
    "            try:\n",
    "                birthday = dparser.parse(raw_age,fuzzy=True, dayfirst = True)\n",
    "                age = birthday.strftime(\"%d/%m/%Y\")\n",
    "            except:\n",
    "                print(\"***cannot parse date from:\", raw_age)\n",
    "    return age, gender\n",
    "\n",
    "def gender_regularization(raw_gender):\n",
    "    age = None\n",
    "    gender = \"\"\n",
    "    count_spliter = raw_gender.count(\":\")\n",
    "\n",
    "    temp_age, temp_gender = check_mixed_age_gender(raw_gender)\n",
    "    if temp_age != None:\n",
    "        age = temp_age\n",
    "    if temp_gender != None:\n",
    "        gender = temp_gender\n",
    "    \n",
    "    elif count_spliter == 1:\n",
    "        left_part, right_part = raw_gender.split(\":\")\n",
    "        left_part = left_part.strip()\n",
    "        right_part = right_part.strip()\n",
    "        for each in GENDER_ANCHOR_LIST:\n",
    "            if each in left_part.lower():\n",
    "                if right_part.lower() == \"nam\":\n",
    "                    gender = \"Nam\"\n",
    "                elif right_part.lower() == \"nữ\":\n",
    "                    gender = \"Nữ\"\n",
    "                break\n",
    "\n",
    "    elif count_spliter == 0:\n",
    "        shorten_gender = raw_gender\n",
    "        for each in GENDER_ANCHOR_LIST:\n",
    "            shorten_gender = raw_gender.replace(each, \"\")\n",
    "        shorten_gender = shorten_gender.strip()\n",
    "        if shorten_gender.lower() == \"nam\":\n",
    "            gender = \"Nam\"\n",
    "        elif shorten_gender.lower() == \"nữ\":\n",
    "            gender = \"Nữ\"\n",
    "\n",
    "    return gender, age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icd_code_parser(raw_diagnose):\n",
    "    diagnose = \" \" + raw_diagnose + \" \"\n",
    "    diagnose = diagnose.replace(\"ICD10\", \"ICD\")\n",
    "    diagnose = diagnose.replace(\"icd10\", \"icd\")\n",
    "    first_pattern = '[,:\\- \\[({;][a-zA-Z]{1}\\d+.\\d+[,:\\- \\])};]'\n",
    "    second_pattern = '[,:\\- \\[({;][a-zA-Z]{1}\\d+[,:\\- \\])};]'\n",
    "    first_result = re.findall(first_pattern, diagnose)\n",
    "    second_result = re.findall(second_pattern, diagnose)\n",
    "\n",
    "    total_result = first_result + second_result\n",
    "    final_result = []\n",
    "    for each in total_result:\n",
    "        end_chars_to_remove = \",.:])}- ;\"\n",
    "        start_chars_to_remove = \",.:[({- ;\"\n",
    "        single_icd = each\n",
    "        if single_icd[-1] in end_chars_to_remove:\n",
    "            single_icd = single_icd[:-1]\n",
    "        if single_icd[0] in start_chars_to_remove:\n",
    "            single_icd = single_icd[1:]\n",
    "        final_result.append(single_icd)\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icd_code_parser(raw_diagnose):\n",
    "    diagnose = \" \" + raw_diagnose + \" \"\n",
    "    diagnose = diagnose.replace(\"ICD10\", \"ICD\")\n",
    "    diagnose = diagnose.replace(\"icd10\", \"icd\")\n",
    "    first_pattern = '(?=([,:\\- \\[({;/]([a-zA-Z]{1}\\d+.\\d+)[.,:\\- \\])};/]))'\n",
    "    second_pattern = '(?=([,:\\- \\[({;/]([a-zA-Z]{1}\\d+)[.,:\\- \\])};/]))'\n",
    "    first_result = re.findall(first_pattern, diagnose)\n",
    "    second_result = re.findall(second_pattern, diagnose)\n",
    "\n",
    "    first_result_unique  = [each[1] for each in first_result]\n",
    "    second_result_unique  = [each[1] for each in second_result]\n",
    "\n",
    "    first_result_idx = [raw_diagnose.index(each) for each in first_result_unique]\n",
    "    second_result_idx = [raw_diagnose.index(each) for each in second_result_unique]\n",
    "\n",
    "    unique_icds = first_result_unique.copy()\n",
    "    for each_idx, val in zip(second_result_idx, second_result_unique):\n",
    "        if each_idx not in first_result_idx:\n",
    "            unique_icds.append(val)\n",
    "    return unique_icds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_diagnose = \"Mã icd10 là:R50.1 R50.2;R50.13/G24\"\n",
    "\n",
    "diagnose = \" \" + raw_diagnose + \" \"\n",
    "diagnose = diagnose.replace(\"ICD10\", \"ICD\")\n",
    "diagnose = diagnose.replace(\"icd10\", \"icd\")\n",
    "first_pattern = '(?=([,:\\- \\[({;/]([a-zA-Z]{1}\\d+.\\d+)[.,:\\- \\])};/]))'\n",
    "second_pattern = '(?=([,:\\- \\[({;/]([a-zA-Z]{1}\\d+)[.,:\\- \\])};/]))'\n",
    "first_result = re.findall(first_pattern, diagnose)\n",
    "second_result = re.findall(second_pattern, diagnose)\n",
    "\n",
    "first_result_unique  = [each[1] for each in first_result]\n",
    "second_result_unique  = [each[1] for each in second_result]\n",
    "\n",
    "first_result_idx = [raw_diagnose.index(each) for each in first_result_unique]\n",
    "second_result_idx = [raw_diagnose.index(each) for each in second_result_unique]\n",
    "\n",
    "unique_icds = first_result_unique.copy()\n",
    "for each_idx, val in zip(second_result_idx, second_result_unique):\n",
    "    if each_idx not in first_result_idx:\n",
    "        unique_icds.append(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_icds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 not in range(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_main_info(kie_df):\n",
    "    #HOSPITAL NAME\n",
    "    extracted_hospital_name =  get_raw_predicted(\"hospital_name\", kie_df, sort_top_down=True)\n",
    "    merged_hospital_name = \" \".join(extracted_hospital_name)\n",
    "    print(\"hospital_name:\", merged_hospital_name)\n",
    "    # if len(extracted_hospital_name)>0:\n",
    "    #     print(\"hospital_name:\", extracted_hospital_name[0])\n",
    "        \n",
    "    #PATIENT NAME\n",
    "    extracted_patient_names =  get_raw_predicted(\"patient_name\", kie_df)\n",
    "    if len(extracted_patient_names)>0:\n",
    "\n",
    "        patient_name = patient_name_regularization(extracted_patient_names[0])\n",
    "        print(\"patient_name:\", patient_name)\n",
    "\n",
    "    #AGE\n",
    "    extracted_ages =  get_raw_predicted(\"age\", kie_df)\n",
    "    if len(extracted_ages)>0:\n",
    "        age, temp_gender = age_regularization(extracted_ages[0])\n",
    "        print(\"age:\", age)\n",
    "        if temp_gender!= None:\n",
    "            print(\"gender:\", temp_gender)\n",
    "\n",
    "    #GENDER\n",
    "    extracted_gender =  get_raw_predicted(\"gender\", kie_df)\n",
    "    if len(extracted_gender)>0:\n",
    "        gender, temp_age = gender_regularization(extracted_gender[0])\n",
    "        print(\"gender:\", gender)\n",
    "        if temp_age!= None:\n",
    "            print(\"age:\", temp_age)\n",
    "\n",
    "    #ADMISION DATE\n",
    "    extracted_admission_date =  get_raw_predicted(\"admission_date\", kie_df)\n",
    "    if len(extracted_admission_date)>0:\n",
    "        for each in extracted_admission_date:\n",
    "            d,m,y = vn_date_parser(each)\n",
    "            admission_date = (d,m,y)\n",
    "            vis_date = f\"{d}/{m}/{y}\"\n",
    "            print(\"admission_date:\", vis_date)\n",
    "\n",
    "    #DISCHARGE DATE\n",
    "    extracted_discharge_date =  get_raw_predicted(\"discharge_date\", kie_df)\n",
    "    if len(extracted_discharge_date)>0:\n",
    "        for each in extracted_discharge_date:\n",
    "            d,m,y = vn_date_parser(each)\n",
    "            discharge_date = (d,m,y)\n",
    "            vis_date = f\"{d}/{m}/{y}\"\n",
    "            print(\"discharge_date:\", vis_date)\n",
    "\n",
    "    #SIGN DATE\n",
    "    extracted_sign_date =  get_raw_predicted(\"sign_date\", kie_df)\n",
    "    if len(extracted_sign_date)>0:\n",
    "        for each in extracted_sign_date:\n",
    "            d,m,y = vn_date_parser(each)\n",
    "            sign_date = (d,m,y)\n",
    "            vis_date = f\"{d}/{m}/{y}\"\n",
    "            print(\"sign_date:\", vis_date)\n",
    "\n",
    "    #ICD CODE\n",
    "    extracted_ICD_code = get_raw_predicted(\"diagnose\", kie_df)\n",
    "    unique_icd_codes = []\n",
    "    if len(extracted_ICD_code)>0:\n",
    "        for each in extracted_ICD_code:\n",
    "            icd_code = icd_code_parser(each)\n",
    "            if icd_code not in unique_icd_codes:\n",
    "                unique_icd_codes += icd_code\n",
    "    remain_field =  get_raw_predicted(\"None\", kie_df) + get_raw_predicted(\"treatment\", kie_df) + get_raw_predicted(\"note\", kie_df)\n",
    "    for each in remain_field:\n",
    "        if \"icd\" in each.lower():\n",
    "            icd_code = icd_code_parser(each)\n",
    "            if icd_code not in unique_icd_codes:\n",
    "                unique_icd_codes += icd_code\n",
    "    print(\"ICD code:\", unique_icd_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_time = time.time()\n",
    "img_idx = \"497\"\n",
    "test_img = cv2.imread(f\"D:/PPYData/rotated_imgs/{img_idx}.jpeg\")\n",
    "test_img = preprocessImage(test_img)\n",
    "\n",
    "result = lineDetAndOCR.begin_recognize_text(test_img)\n",
    "kie_df = kieGCN(result, test_img)\n",
    "print(\"Total processing time:\", time.time() - s_time)\n",
    "print(\"--------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_idx = \"985\"\n",
    "import json\n",
    "Docbase_path = \"D:/PPYData/DPJson/\"\n",
    "fp = Docbase_path+f\"{img_idx}.jpeg.json\"\n",
    "js_path = json.load(open(fp, encoding=\"utf-8\"))\n",
    "\n",
    "temp_list_db_icd = js_path[\"data\"][0][\"info\"][\"icd_10\"]\n",
    "db_icd = []\n",
    "for each in temp_list_db_icd:\n",
    "    db_icd.append(each[0])\n",
    "\n",
    "db_hospital_name = js_path[\"data\"][0][\"info\"][\"medical_facility\"]\n",
    "db_gender = js_path[\"data\"][0][\"info\"][\"gender\"]\n",
    "db_discharge_date = js_path[\"data\"][0][\"info\"][\"hospital_discharge_date\"]\n",
    "db_admisstion_date = js_path[\"data\"][0][\"info\"][\"hospitalization_date\"]\n",
    "db_patient_name = js_path[\"data\"][0][\"info\"][\"patient_name\"]\n",
    "db_age = js_path[\"data\"][0][\"info\"][\"year_of_birth\"]\n",
    "\n",
    "print(\"hospital_name:\", db_hospital_name)\n",
    "print(\"patient_name:\", db_patient_name)\n",
    "print(\"age:\", db_age)\n",
    "print(\"gender:\", db_gender)\n",
    "print(\"admisstion_date:\", db_admisstion_date)\n",
    "print(\"discharge_date:\", db_discharge_date)\n",
    "print(\"ICD code:\", db_icd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_main_info(kie_df)\n",
    "from PIL import Image\n",
    "img = Image.open(r\"temp_data\\temp_gcn\\img\\temp.jpg\")\n",
    "display(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for img_idx in range(227, 241):\n",
    "    try:\n",
    "        s_time = time.time()\n",
    "        img_idx = str(img_idx)\n",
    "        test_img = cv2.imread(f\"D:/PPYData/rotated_imgs/{img_idx}.jpeg\")\n",
    "        test_img = preprocessImage(test_img)\n",
    "\n",
    "        result = lineDetAndOCR.begin_recognize_text(test_img)\n",
    "        kie_df = kieGCN(result, test_img)\n",
    "        print(\"Total processing time:\", time.time() - s_time)\n",
    "        print(\"--------------------\")\n",
    "\n",
    "        current_annotation = []\n",
    "        for idx in range(len(kie_df)):\n",
    "            row = kie_df.iloc[idx]\n",
    "            transcription = row[\"Object\"]\n",
    "            polygon = ast.literal_eval(row[\"polygon\"])\n",
    "            points = [list(each) for each in polygon]\n",
    "            key_cls = row[\"pred_label\"]\n",
    "            cur_dict = {\n",
    "                \"transcription\":transcription,\n",
    "                \"points\":points,\n",
    "                \"difficult\":False,\n",
    "                \"key_cls\":key_cls\n",
    "            }\n",
    "            current_annotation.append(cur_dict)\n",
    "\n",
    "        cur_line = f\"test/{img_idx}.jpeg\\t{current_annotation}\"\n",
    "        with open(r\"D:\\PPYData\\test\\Label.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "            f.writelines(cur_line+\"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR at {img_idx}\")\n",
    "        print(e)\n",
    "        print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_diagnose = kie_df[kie_df[\"pred_label\"] == \"diagnose\"][\"Object\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_diagnose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in list_diagnose:\n",
    "    icds = icd_code_parser(each)\n",
    "    print(icds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '- Thường]:K21-Bệnh trảo ng'\n",
    "pt = '[a-zA-Z]{1}\\d+[:\\- \\])}]'\n",
    "\n",
    "result = re.findall(pt, s)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date_with_re(raw_date):\n",
    "    pattern = \"\\d+[/-]\\d+[/-]\\d+\"\n",
    "    temp_date = raw_date.replace(\"\\\\\",\"/\")\n",
    "    temp_date = re.findall(pattern=pattern, string=temp_date)\n",
    "    list_result = []\n",
    "    for each in temp_date:\n",
    "        for splitter in [\"/\", \"-\"]:\n",
    "            if splitter in each:\n",
    "                d, m, y = each.split(splitter)\n",
    "                list_result.append((d,m,y))\n",
    "                break\n",
    "    return list_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icd_code_parser(raw_diagnose):\n",
    "    diagnose = raw_diagnose\n",
    "    first_pattern = '[a-zA-Z]{1}\\d+.\\d+[:\\- \\])}]'\n",
    "    second_pattern = '[a-zA-Z]{1}\\d+[:\\- \\])}]'\n",
    "    first_result = re.findall(first_pattern, diagnose)\n",
    "    second_result = re.findall(second_pattern, diagnose)\n",
    "\n",
    "    total_result = first_result + second_result\n",
    "    final_result = []\n",
    "    for each in total_result:\n",
    "        chars_to_remove = \",.:])-} \"\n",
    "        if each[-1] in chars_to_remove:\n",
    "            single_icd = each[:-1]\n",
    "            final_result.append(single_icd)\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = r\"Hôm nay là ngày 21\\102022\"\n",
    "dmy = parse_date_with_re(s)\n",
    "dmy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = 2\n",
    "c = 3\n",
    "d = a+b\n",
    "e = d+c\n",
    "print(d)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import postprocess\n",
    "import importlib\n",
    "importlib.reload(postprocess)\n",
    "kiePostprocess = postprocess.KiePostProcess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiePostprocess.append_kie_df(kie_df)\n",
    "\n",
    "hospital_name = kiePostprocess.hospital_name_postprocess()\n",
    "print(\"hospital_name:\", hospital_name)\n",
    "\n",
    "patient_name = kiePostprocess.patient_name_postprocess()\n",
    "print(\"patient_name:\", patient_name)\n",
    "\n",
    "age, temp_gender = kiePostprocess.age_postprocess()\n",
    "gender, temp_age = kiePostprocess.gender_postprocess()\n",
    "if age == None and temp_age != None:\n",
    "    age = temp_age\n",
    "if gender == None and temp_gender != None:\n",
    "    gender = temp_gender\n",
    "\n",
    "if age == None:\n",
    "    age = kiePostprocess.find_age_remain()\n",
    "print(\"gender:\", gender)\n",
    "print(\"age:\", age)\n",
    "\n",
    "admissiion_dates = kiePostprocess.admission_date_postprocess()\n",
    "for each in admissiion_dates:\n",
    "    print(\"admissiion_date:\", each)\n",
    "\n",
    "discharge_dates = kiePostprocess.discharge_date_postprocess()\n",
    "for each in discharge_dates:\n",
    "    print(\"discharge_date:\", each)\n",
    "\n",
    "sign_dates = kiePostprocess.sign_date_postprocess()\n",
    "for each in sign_dates:\n",
    "    print(\"sign_date:\", each)\n",
    "\n",
    "\n",
    "ICD_codes = kiePostprocess.ICD_code_postprocess()\n",
    "print(\"ICD_codes:\", ICD_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import e2e_process\n",
    "from kie_gcn import InvoiceGCN\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_OCR_Engine = e2e_process.E2E_OCR_Engine(\n",
    "    detection_model_path=\"./PaddleOCR/pretrained_models/exported_det_model_221011\",\n",
    "    text_recognition_model_path=\"./weights/ocr/ocr_221026.pth\",\n",
    "    gcn_model_path=\"./weights/./gcn/GCN_221027_best.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"D:/PPYData/discharge_paper/11102022/52.jpeg\"\n",
    "# img_path = r\"D:/PPYData/image/977.jpeg\"\n",
    "result, extracted_df = e2e_OCR_Engine(img_path)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_path)\n",
    "display(Image.fromarray(cv2.cvtColor(img, cv2.COLOR_RGB2BGR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import postprocess\n",
    "import importlib\n",
    "import pandas as pd\n",
    "importlib.reload(postprocess)\n",
    "x = postprocess.KiePostProcess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.age_regularization(\"- Năm Sinh: 2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.icd_code_parser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "import re\n",
    "raw_date = \"ngay 5812-2-202\"\n",
    "pattern = r\"\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\"\n",
    "temp_date = raw_date.replace(\"\\\\\",\"/\")\n",
    "temp_date = raw_date.replace(\" \",\"\")\n",
    "temp_date = re.findall(pattern=pattern, string=temp_date)\n",
    "temp_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"\")\n",
    "df.to_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:15:33) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31ffcf7a35e8fb622d3a4bd4bd659d058512ef6f478d0fb17b526c56291289f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
